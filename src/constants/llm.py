LLM_MODEL = "meta-llama/Llama-3.1-8B-Instruct"
MAX_NEW_TOKEN = 3000
DO_SAMPLE = True
TEMPERATURE = 0.2
PROMPT_MAX_TOKEN = 8000
BATCH_SIZE = 24
